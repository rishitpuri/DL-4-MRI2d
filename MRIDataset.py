import os
import torch
import pandas as pd
from PIL import Image
from torch.utils.data import Dataset

# Dataframe
"""
Image Patient ID SNP1 SNP2 SNP3 SNP4
"""

"""
A more efficient way to achieve the same can be found at:
# https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#:~:text=4%2C%2068%2C%202%5D)-,Afterword%3A%20torchvision,-In%20this%20tutorial

Recommended for all future versions to minimize bloat
"""
class MRI2DDataset(Dataset):
    """ A torch dataset class enabling efficient loading of MRI images"""

    def __init__(self, root_dir, transform=None):
        """Initialize the root_directory

        Args:
            root_dir (string): file path
            transform (callable, optional): Optional transform that can be applied to dataset. Defaults to None.
        """
        self.size = 0
        self.map = dict()
        self.root = root_dir
        self.transform = transform
        self.data = self._load_data()

    def __len__(self):
        """Return the number of items in the dataset"""
        return self.size
    
    def _load_data(self):
        """Loads a list containing path of images and their respective labels into memory

        Returns:
            list: contains a tuple containing the path of the image and the label (path:string, label:string)
        """
        children = 0
        labels = list()
        filepath = list()
        subtypes = os.listdir(self.root)
        
        for label,subtype in enumerate(subtypes):
            subtype_dir = os.path.join(self.root, subtype)
            if os.path.isdir(subtype_dir):
                for filename in os.listdir(subtype_dir):
                    if filename.endswith(('.jpg', '.jpeg', '.png')):
                        file_path = os.path.join(subtype_dir, filename)
                        filepath.append(file_path)
                        labels.append(label)
                        children += 1
        
        self.size = children
        data = pd.DataFrame({'file_path':filepath, 'label':labels})
        self.map = {subtype:label for label, subtype in enumerate(subtypes)}
        return data

    def __getitem__(self, idx):
        """Fetch the image and the corresponding label

        Args:
            idx (tensor, int): The index generated by the DataLoader class
        """
        if torch.is_tensor(idx):
            idx = idx.tolist()
        
        label = self.data.iloc[idx,1]
        img_path = self.data.iloc[idx,0]
        image = Image.open(img_path).convert('L')

        if self.transform:
            image = self.transform(image)
        
        return {'image':image, 'label':label}
        
        
        
"""
Example Usage:

dataset = MRI2DDataset(root_dir='./Dataset')
print(len(dataset))

for i in range(0,len(dataset)):
    print(dataset[i]['label'])

PS: ChatGPT DID NOT write this
"""